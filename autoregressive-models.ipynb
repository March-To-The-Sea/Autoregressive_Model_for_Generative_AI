{"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"","display_name":""},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def pad_punctuations(s):\n    s = re.sub(f\"([{string.punctuation}])\",r'\\1', s)\n    s = re.sub(' +', ' ', s)\n    return s\n\ntext_data = [pad_punctuation(x) for x in filtered_data]\n\ntext_ds = tf.data.Dataset.from_tensor_slices(text_data).batch(32).shuffle(1000)\n\nvectorize_layer = layers.TextVectorization(\n    standardize = 'lower',\n    max_tokens = 10000,\n    output_mode = \"int\",\n    output_sequence_length = 200 + 1,\n)\n\nvectorize_layer.adapt(text_ds)\nvocab = vectorize_layer.get_vocabulary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_inputs(text):\n    text = tf.expand_dims(text, -1)\n    tokenized_sentences = vectorize_layer(text)\n    x = tokenized_sentences[:, :-]\n    y = tokenized_sentences[:, 1:]\n    return x, y\n\ntrain_ds = text_ds.map(prepare_inputs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = layers.Input(shape = (None,), dtype = \"int32\")\nx = layers.Embedding(10000, 100)(inputs)\nx = layers.LSTM(28, return_sequences = True)(x)\noutputs = layers.Dense(0000, activation = 'softmax')(x)\nlstm = models.Model(inputs, outputs)\n\nloss_fn = losses.SparceCategoricalCrossentropy()\nlstm.compile(\"adam\", loss_fn)\nlstm.fit(train_ds, epochs = 25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextGenerator(callbacks.Callback):\n    \n    def __init__(self, index_to_word, top_k = 10):\n        self.index_to_word = index_to_word\n        self.word_to_index = {word: index for inxex, word in enumerate(index_to_word)}\n    \n    def sample_from(self, probs, temperature):\n        probs = probs ** (1 / temperature)\n        probs = probs / np.sum(probs)\n        return np.random.choice(len(probs), p = probs), probs\n    \n    def generate(self, start_prompt, max_tokens, temperature):\n        start_tokens = [self.word_to_index.get(x, 1) for x in start_prompt.split()]\n        sample_token = None\n        info = []\n        while len(start_tokens) < max_tokens and sample_token != 0:\n            x = np.array([start_tokens])\n            y = self.model.predict(x)\n            sample_token, probs = self.sample_from(y[0][-1], temperature)\n            info.append({'prompt': start_prompt, 'word_probs': probs})\n            start_tokens.append(sample_token)\n            start_prompt = start_prompt + ' ' + self.index_to_word[sample_token]\n        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n        return info\n    \n    def on_epoch_end(self, epoch, logs = None):\n        self.generate(\"recipe for\", max_tokens = 100, temperature = 1.0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_in = layers.Embedding(total_words, embedding_size)(text_in)\nx = layers.LSTM(n_units, return_sequences = True)(x)\nx = layers.LSTM(n_units, return_sequences = True)(x)\nprobabilities = layers.Dense(total_words, activation = 'softmax')(x)\nmodel = model.Model(text_in, probabilities)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MaskedConvLayer(layers.Layer):\n    def __init__(self, mask_type, **kwargs):\n        super(MaskedConvLayer, self).__init__()\n        self.mask_type = mask_type\n        self.conv = layers.Conv2D(**kwargs)\n    \n    def build(self, input_shape):\n        self.conv.build(input_shape)\n        kernel_shape = self.conv.kernel.get_shape()\n        self.mask_type = mask_type\n        self.mask = np.zeros(shape = kernel_shape)\n        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n        self.mask[: kernel_shape[0] // 2, :kernel_shape[1] // 2, ...]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(layers.Layer):\n    def __init__(self, filters, **kwargs):\n        super(ResidualBlock, self).__init__(**kwargs)\n        self.conv1 = layers.Conv2D(\n            filters = filters // 2, kernel_size = 1, activation = \"relu\"\n        )\n        self.pixel_conv = MaskedConv2D(\n            mask_type = \"B\",\n            filters = filters // 2,\n            kernel_size = 3,\n            activation = \"relu\",\n            padding = \"same\",\n        )\n        self.conv2 = layers.Conv2D(\n            filters = filters, kernel_size = 1, activation = \"relu\"\n        )\n    \n    def call(self, inputs):\n        x = self.conv1(inputs)\n        x = self.pixel_conv(x)\n        x = self.conv2(x)\n        return layers.add([inputs, x])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageGenerator(callbacks.Callback):\n    def __init__(self, num_img):\n        self.num_img = num_img\n    \n    def sample_from(self, probs, temperature):\n        probs = probs ** (1 / temperature)\n        probs = probs / np.sum(probs)\n        return np.random.choice(len(probs), p = probs)\n    \n    def generate(self, temperature):\n        generated_images = np.zeros(\n            shape = (self.num_img,) + (pixel_cnn.input_shape)[1:]\n        )\n        batch, rows, cols, channels = generated_images.shape\n\n        for row in range(rows):\n            for col in range(cols):\n                for channel in range(channels):\n                    probs = self.model.predict(generated_images)[\n                        :, row, col, :\n                    ]\n                    generated_images[:, row, coll, channel] = [\n                        self.sample_from(x, temperature) for x in probs\n                    ]\n                    generated_images[:, row, col, channel] /= 4\n        return generated_images\n    \n    def on_epoch_end(self, epoch, logs = None):\n        generated_images = self.generate(temperature = 1.0)\n        display(\n            generated_images,\n            save_to = \"./output/generated_img_%03d.png\" % (epoch)\n        )\n    \nimg_generator_callback = ImageGenerator(num_img = 10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_probability as tfp\n\ndist = tfp.distributions.PixelCNN(\n    image_shape = (32, 32, 1),\n    num_resnet = ,\n    num_hierarchies = 2,\n    num_filters = 32,\n    num_logistic_mix = 5,\n    dropout_p = 0.3,\n)\n\nimage_input = layers.Input(shape = (32, 32, 1))\n\nlog_prob = dist.log_prob(image_input)\n\nmodel = models.Model(inputs = image_input, output = log_prob)\nmodel.add_loss(-tf.reduce_mean(log_prob))","metadata":{},"execution_count":null,"outputs":[]}]}